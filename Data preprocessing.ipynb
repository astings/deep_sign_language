{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv as csv\n",
    "from random import randint\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def csv2data(file_str):\n",
    "    data_str = csv.reader(open(file_str, encoding = \"ISO-8859-1\"), delimiter='\\n')\n",
    "    data = []\n",
    "    for row in data_str:\n",
    "        data.append(row[0])    \n",
    "    return data\n",
    "\n",
    "corpus = csv2data('liste_francais.csv')\n",
    "\n",
    "def clean_dict(dictionary):\n",
    "    new_dict = []\n",
    "    for word in dictionary:\n",
    "        if((len(list(word))>=4) and (len(word.split(' '))==1) and re.match(\"^[a-zA-Z]*$\", word) and re.match(\"^[^j|J|z|Z]*$\", word)) and word[0].islower():\n",
    "            new_dict.append(word)\n",
    "    \n",
    "    return new_dict\n",
    "\n",
    "corpus = clean_dict(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13489"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv2images(file_str):\n",
    "    data_str = csv.reader(open(file_str), delimiter='\\n', quotechar='|')\n",
    "    data = []\n",
    "    next(data_str)\n",
    "    for row in data_str:\n",
    "        each_row = ','.join(row)\n",
    "        row_arr = list(map(int, each_row.split(',')))\n",
    "        data.append(row_arr)\n",
    "    \n",
    "    return data\n",
    "\n",
    "train_images = csv2images('sign_mnist_train.csv')\n",
    "test_images = csv2images('sign_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_lists(dictionary, \n",
    "                         num_of_features=200, \n",
    "                         num_of_mutations=1, \n",
    "                         test_percentage=0.1, \n",
    "                         true_percentage=0.8): \n",
    " \n",
    "    train_word_list = []\n",
    "    test_word_list = []\n",
    "        \n",
    "    n_of_misspellings = math.floor((1-true_percentage)*num_of_features)\n",
    "    n_of_tests = math.floor(test_percentage*num_of_features)\n",
    "    \n",
    "    for word in dictionary:\n",
    "        row = []\n",
    "        for fea in range(n_of_misspellings):\n",
    "            \n",
    "            row.append(gen_misspellings(word, num_of_mutations))\n",
    "        \n",
    "        train_row, test_row = train_test_split(row, test_size=test_percentage)\n",
    "        \n",
    "        train_row.extend([word]*math.ceil((num_of_features - n_of_misspellings)*(1 - test_percentage)))\n",
    "        test_row.extend([word]*math.ceil((num_of_features - n_of_misspellings)*(test_percentage)))       \n",
    "        \n",
    "        train_word_list.append(train_row)\n",
    "        test_word_list.append(test_row)\n",
    "        \n",
    "    return train_word_list,test_word_list\n",
    "\n",
    "\n",
    "def gen_misspellings(word, mut=1): \n",
    "    \n",
    "    alphabet = ['a','b','c','d','e','f','g','h','i','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y']\n",
    "    char_arr = list(word)\n",
    "    \n",
    "    for muts in range(mut):        \n",
    "        mut_idx = randint(0, len(word)-1)\n",
    "        char_arr[mut_idx] = alphabet[randint(0,23)] \n",
    "\n",
    "    return \"\".join(char_arr)\n",
    "\n",
    "train_words, test_words = get_words_lists(corpus, 200, 1, 0.1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_buckets(images):\n",
    "    \n",
    "    buckets = [[] for _ in range(25)]\n",
    "\n",
    "    for idx, sample in enumerate(images):\n",
    "        buckets[int(sample[0])].append(idx)\n",
    "        \n",
    "    return buckets\n",
    "\n",
    "train_buckets = create_buckets(train_images)\n",
    "test_buckets = create_buckets(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_LSTM_data(words, buckets):\n",
    "    \n",
    "    data = [];\n",
    "    for sample in words:\n",
    "        label = sample[-1]\n",
    "        label_arr = [ord(char) - 96 for char in label.lower()]\n",
    "        for word in sample:\n",
    "            reference = [ord(char) - 96 for char in word.lower()]\n",
    "            idx_arr = []\n",
    "            for ele in reference:\n",
    "                idx_arr.append(buckets[ele - 1][randint(0, len(buckets[ele - 1]) - 1)])\n",
    "            data.append((word, reference, label, label_arr))\n",
    "\n",
    "    return data\n",
    "\n",
    "train_data = generate_LSTM_data(train_words, train_buckets)\n",
    "test_data = generate_LSTM_data(test_words, test_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_indexes(full_data):\n",
    "    \n",
    "    item_1=[item[1] for item in full_data]\n",
    "    idxs=([torch.LongTensor(xi) for xi in item_1])\n",
    "    item_3=[item[3] for item in full_data]\n",
    "    labels=([torch.LongTensor(xi) for xi in item_3])\n",
    "    \n",
    "    return idxs, labels\n",
    "\n",
    "train_index, train_labels =split_indexes(train_data)\n",
    "test_index, test_labels=split_indexes(test_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
